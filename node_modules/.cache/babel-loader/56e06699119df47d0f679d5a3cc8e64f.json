{"ast":null,"code":"'use strict';\n\nconst urlRegex = require('url-regex-safe');\n\nconst normalizeUrl = require('normalize-url');\n\nconst getUrlsFromQueryParameters = url => {\n  const returnValue = new Set();\n  const {\n    searchParams\n  } = new URL(url.replace(/^(?:\\/\\/|(?:www\\.))/i, 'http://$2'));\n\n  for (const [, value] of searchParams) {\n    if (urlRegex({\n      exact: true\n    }).test(value)) {\n      returnValue.add(value);\n    }\n  }\n\n  return returnValue;\n};\n\nmodule.exports = (text, options = {}) => {\n  if (typeof text !== 'string') {\n    throw new TypeError(`The \\`text\\` argument should be a string, got ${typeof text}`);\n  }\n\n  if (typeof options.exclude !== 'undefined' && !Array.isArray(options.exclude)) {\n    throw new TypeError('The `exclude` option must be an array');\n  }\n\n  const returnValue = new Set();\n\n  const add = url => {\n    try {\n      returnValue.add(normalizeUrl(url.trim().replace(/\\.+$/, ''), options));\n    } catch {}\n  };\n\n  const urls = text.match(urlRegex(options.requireSchemeOrWww === undefined ? undefined : {\n    strict: options.requireSchemeOrWww\n  })) || [];\n\n  for (const url of urls) {\n    add(url);\n\n    if (options.extractFromQueryString) {\n      const qsUrls = getUrlsFromQueryParameters(url);\n\n      for (const qsUrl of qsUrls) {\n        add(qsUrl);\n      }\n    }\n  }\n\n  for (const excludedItem of options.exclude || []) {\n    for (const item of returnValue) {\n      const regex = new RegExp(excludedItem);\n\n      if (regex.test(item)) {\n        returnValue.delete(item);\n      }\n    }\n  }\n\n  return returnValue;\n};","map":{"version":3,"sources":["C:/Users/twist/OneDrive/Documents/react/build-twitter-with-react/node_modules/get-urls/index.js"],"names":["urlRegex","require","normalizeUrl","getUrlsFromQueryParameters","url","returnValue","Set","searchParams","URL","replace","value","exact","test","add","module","exports","text","options","TypeError","exclude","Array","isArray","trim","urls","match","requireSchemeOrWww","undefined","strict","extractFromQueryString","qsUrls","qsUrl","excludedItem","item","regex","RegExp","delete"],"mappings":"AAAA;;AACA,MAAMA,QAAQ,GAAGC,OAAO,CAAC,gBAAD,CAAxB;;AACA,MAAMC,YAAY,GAAGD,OAAO,CAAC,eAAD,CAA5B;;AAEA,MAAME,0BAA0B,GAAGC,GAAG,IAAI;AACzC,QAAMC,WAAW,GAAG,IAAIC,GAAJ,EAApB;AACA,QAAM;AAACC,IAAAA;AAAD,MAAkB,IAAIC,GAAJ,CAAQJ,GAAG,CAACK,OAAJ,CAAY,sBAAZ,EAAoC,WAApC,CAAR,CAAxB;;AAEA,OAAK,MAAM,GAAGC,KAAH,CAAX,IAAwBH,YAAxB,EAAsC;AACrC,QAAIP,QAAQ,CAAC;AAACW,MAAAA,KAAK,EAAE;AAAR,KAAD,CAAR,CAAwBC,IAAxB,CAA6BF,KAA7B,CAAJ,EAAyC;AACxCL,MAAAA,WAAW,CAACQ,GAAZ,CAAgBH,KAAhB;AACA;AACD;;AAED,SAAOL,WAAP;AACA,CAXD;;AAaAS,MAAM,CAACC,OAAP,GAAiB,CAACC,IAAD,EAAOC,OAAO,GAAG,EAAjB,KAAwB;AACxC,MAAI,OAAOD,IAAP,KAAgB,QAApB,EAA8B;AAC7B,UAAM,IAAIE,SAAJ,CAAe,iDAAgD,OAAOF,IAAK,EAA3E,CAAN;AACA;;AAED,MAAI,OAAOC,OAAO,CAACE,OAAf,KAA2B,WAA3B,IAA0C,CAACC,KAAK,CAACC,OAAN,CAAcJ,OAAO,CAACE,OAAtB,CAA/C,EAA+E;AAC9E,UAAM,IAAID,SAAJ,CAAc,uCAAd,CAAN;AACA;;AAED,QAAMb,WAAW,GAAG,IAAIC,GAAJ,EAApB;;AAEA,QAAMO,GAAG,GAAGT,GAAG,IAAI;AAClB,QAAI;AACHC,MAAAA,WAAW,CAACQ,GAAZ,CAAgBX,YAAY,CAACE,GAAG,CAACkB,IAAJ,GAAWb,OAAX,CAAmB,MAAnB,EAA2B,EAA3B,CAAD,EAAiCQ,OAAjC,CAA5B;AACA,KAFD,CAEE,MAAM,CAAE;AACV,GAJD;;AAMA,QAAMM,IAAI,GAAGP,IAAI,CAACQ,KAAL,CACZxB,QAAQ,CAACiB,OAAO,CAACQ,kBAAR,KAA+BC,SAA/B,GAA2CA,SAA3C,GAAuD;AAC/DC,IAAAA,MAAM,EAAEV,OAAO,CAACQ;AAD+C,GAAxD,CADI,KAIR,EAJL;;AAKA,OAAK,MAAMrB,GAAX,IAAkBmB,IAAlB,EAAwB;AACvBV,IAAAA,GAAG,CAACT,GAAD,CAAH;;AAEA,QAAIa,OAAO,CAACW,sBAAZ,EAAoC;AACnC,YAAMC,MAAM,GAAG1B,0BAA0B,CAACC,GAAD,CAAzC;;AACA,WAAK,MAAM0B,KAAX,IAAoBD,MAApB,EAA4B;AAC3BhB,QAAAA,GAAG,CAACiB,KAAD,CAAH;AACA;AACD;AACD;;AAED,OAAK,MAAMC,YAAX,IAA2Bd,OAAO,CAACE,OAAR,IAAmB,EAA9C,EAAkD;AACjD,SAAK,MAAMa,IAAX,IAAmB3B,WAAnB,EAAgC;AAC/B,YAAM4B,KAAK,GAAG,IAAIC,MAAJ,CAAWH,YAAX,CAAd;;AACA,UAAIE,KAAK,CAACrB,IAAN,CAAWoB,IAAX,CAAJ,EAAsB;AACrB3B,QAAAA,WAAW,CAAC8B,MAAZ,CAAmBH,IAAnB;AACA;AACD;AACD;;AAED,SAAO3B,WAAP;AACA,CA3CD","sourcesContent":["'use strict';\nconst urlRegex = require('url-regex-safe');\nconst normalizeUrl = require('normalize-url');\n\nconst getUrlsFromQueryParameters = url => {\n\tconst returnValue = new Set();\n\tconst {searchParams} = (new URL(url.replace(/^(?:\\/\\/|(?:www\\.))/i, 'http://$2')));\n\n\tfor (const [, value] of searchParams) {\n\t\tif (urlRegex({exact: true}).test(value)) {\n\t\t\treturnValue.add(value);\n\t\t}\n\t}\n\n\treturn returnValue;\n};\n\nmodule.exports = (text, options = {}) => {\n\tif (typeof text !== 'string') {\n\t\tthrow new TypeError(`The \\`text\\` argument should be a string, got ${typeof text}`);\n\t}\n\n\tif (typeof options.exclude !== 'undefined' && !Array.isArray(options.exclude)) {\n\t\tthrow new TypeError('The `exclude` option must be an array');\n\t}\n\n\tconst returnValue = new Set();\n\n\tconst add = url => {\n\t\ttry {\n\t\t\treturnValue.add(normalizeUrl(url.trim().replace(/\\.+$/, ''), options));\n\t\t} catch {}\n\t};\n\n\tconst urls = text.match(\n\t\turlRegex(options.requireSchemeOrWww === undefined ? undefined : {\n\t\t\tstrict: options.requireSchemeOrWww\n\t\t})\n\t) || [];\n\tfor (const url of urls) {\n\t\tadd(url);\n\n\t\tif (options.extractFromQueryString) {\n\t\t\tconst qsUrls = getUrlsFromQueryParameters(url);\n\t\t\tfor (const qsUrl of qsUrls) {\n\t\t\t\tadd(qsUrl);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (const excludedItem of options.exclude || []) {\n\t\tfor (const item of returnValue) {\n\t\t\tconst regex = new RegExp(excludedItem);\n\t\t\tif (regex.test(item)) {\n\t\t\t\treturnValue.delete(item);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn returnValue;\n};\n"]},"metadata":{},"sourceType":"script"}